# Smart Inference AI Fusion

Um framework modular e extensÃ­vel para experimentos de inferÃªncia sintÃ©tica e perturbaÃ§Ãµes controladas em algoritmos de InteligÃªncia Artificial (IA), com foco em robustez, variabilidade e testes de falhas em dados e parÃ¢metros.


## ğŸ“ Estrutura do Projeto

```
smart-inference-ai-fusion/
â”œâ”€â”€ main.py                      # Ponto de entrada principal para execuÃ§Ã£o dos experiments
â”œâ”€â”€ run.sh                       # Script utilitÃ¡rio para execuÃ§Ã£o rÃ¡pida
â”œâ”€â”€ datasets/                    # Arquivos CSV utilizados por loaders do tipo CSVDatasetLoader
â”œâ”€â”€ experiments/                 # Experimentos organizados por dataset (ex: iris/, wine/)
â”‚   â””â”€â”€ iris/
â”‚       â”œâ”€â”€ knn_iris.py          # KNN aplicado ao dataset Iris
â”‚       â”œâ”€â”€ svm_iris.py          # SVM aplicado ao dataset Iris
â”‚       â”œâ”€â”€ run_all.py           # Executa todos os experimentos do Iris
â”‚       â””â”€â”€ ...
â”œâ”€â”€ results/                     # Resultados e logs de inferÃªncia (ex: parÃ¢metros perturbados)
â”œâ”€â”€ src/                         # CÃ³digo-fonte principal do framework
â”‚   â”œâ”€â”€ core/                    # Classes base para Experiment, Model e Dataset
â”‚   â”œâ”€â”€ datasets/                # Factory e loaders de datasets (sklearn, csv, etc.)
â”‚   â”œâ”€â”€ inference/               # MÃ³dulo de inferÃªncia
â”‚   â”‚   â”œâ”€â”€ engine/              # Orquestradores de inferÃªncia (InferenceEngine, LabelRunner, etc.)
â”‚   â”‚   â”œâ”€â”€ pipeline/            # Pipeline unificada que aplica todas as inferÃªncias
â”‚   â”‚   â”œâ”€â”€ transformations/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/            # TÃ©cnicas aplicadas aos dados de entrada (X)
â”‚   â”‚   â”‚   â”œâ”€â”€ label/           # TÃ©cnicas aplicadas aos rÃ³tulos (y)
â”‚   â”‚   â”‚   â””â”€â”€ params/          # EstratÃ©gias de perturbaÃ§Ã£o nos parÃ¢metros
â”‚   â”œâ”€â”€ models/                  # ImplementaÃ§Ãµes dos modelos de IA (KNN, SVM, Tree, etc.)
â”‚   â”œâ”€â”€ utils/                   # RelatÃ³rios, enums, tipos e mÃ©tricas
â”‚   â”‚   â””â”€â”€ types.py             # Tipos pydantic e enums como DatasetSourceType, ReportMode
â””â”€â”€ requirements.txt             # Lista de dependÃªncias do projeto

```

## ğŸš€ Executando

### Ambiente recomendado:
- Python 3.10+
- Ambiente virtual (ex: `venv` ou `conda`)

### InstalaÃ§Ã£o:

```bash
pip install -r requirements.txt
```

### ExecuÃ§Ã£o dos experimentos:

```bash
# Forma recomendada
./run.sh

# Ou manualmente:
PYTHONPATH=src python main.py
```

## ğŸ§ª Adicionando novos experimentos

Um experimento representa a aplicaÃ§Ã£o de um algoritmo a um dataset, com ou sem inferÃªncia aplicada (nos dados e/ou nos parÃ¢metros).


### âœ… 1. Escolha e carregue o **dataset**

Utilize a `DatasetFactory` para criar dinamicamente o carregador com o dataset na origem (`sklearn`, `csv`, etc):

```python
from datasets.factory import DatasetFactory
from utils.types import DatasetSourceType, SklearnDatasetName

dataset = DatasetFactory.create(
    source_type=DatasetSourceType.SKLEARN,
    name=SklearnDatasetName.IRIS
)
```

Para dataset externos (ex: `.csv`), troque o tipo e informe o caminho:
```python
dataset = DatasetFactory.create(
    source_type=DatasetSourceType.CSV,
    path="datasets/wine/wine.csv",
    label_column="target"
)
```

### âœ… 2. Defina o modelo (algoritmo de IA):

Importe o modelo desejado e configure os parÃ¢metros base:

```python
from models.knn_model import KNNModel
base_params = {"n_neighbors": 3, "weights": "uniform"}
model = KNNModel(base_params)
```

###  âœ… 3. Adicione inferÃªncia com o `InferencePipeline`

#### âœ… 3.1 InferÃªncia nos parÃ¢metros
Use a funÃ§Ã£o `apply_param_inference` para aplicar perturbaÃ§Ãµes nos hiperparÃ¢metros:
```python
from inference.pipeline.inference_pipeline import InferencePipeline

pipeline = InferencePipeline()

model, param_log = pipeline.apply_param_inference(
    model_class=KNNModel,
    base_params=base_params,
    seed=42,
    ignore_rules={"weights"}
)
```

#### âœ… 3.2 InferÃªncia nos dados (X) e nos rÃ³tulos (y)
- Crie o dicionÃ¡rio com as configuraÃ§Ãµes de perturbaÃ§Ã£o validadas por Pydantic:
```python
from utils.types import DatasetNoiseConfig

dataset_noise_config = DatasetNoiseConfig(
    noise_level=0.2,
    truncate_decimals=1,
    quantize_bins=5,
    cast_to_int=False,
    shuffle_fraction=0.1,
    scale_range=(0.8, 1.2),
    zero_out_fraction=0.05,
    insert_nan_fraction=0.05,
    outlier_fraction=0.05,
    add_dummy_features=2,
    duplicate_features=2,
    feature_selective_noise=(0.3, [0, 2]),
    remove_features=[1, 3],
    feature_swap=[0, 2],
    label_noise_fraction=0.1
)
```

#### âœ… 3.3 Aplique a inferÃªncia com `InferencePipeline`
```python
pipeline = InferencePipeline(dataset_noise_config=dataset_noise_config)

X_train, X_test, y_train, y_test = dataset.load_data()

X_train, X_test = pipeline.apply_data_inference(X_train, X_test)
y_train, y_test = pipeline.apply_label_inference(y_train, y_test)
```

### âœ… 4. Execute o experimento:

Monte o experimento com ou sem inferÃªncia:
```python
from core.experiment import Experiment

experiment = Experiment(model, dataset)
metrics = experiment.run(X_train, X_test, y_train, y_test)
```

### âœ… 5. Reporte os resultados:
```python
from utils.report import report_data, ReportMode

report_data(metrics, mode=ReportMode.PRINT)
report_data(param_log, mode=ReportMode.JSON, file_path="results/knn_param_log.json")
```

### âœ… 6. Integre ao sistema de execuÃ§Ã£o:
- Crie uma funÃ§Ã£o run() que chame:
```python
run_<algoritmo>_without_inference()
run_<algoritmo>_with_inference()
```
- Registre essa funÃ§Ã£o em `experiments/<dataset>/run_all.py`

- Inclua no `__init__.py` da pasta `experiments/<dataset>/`

---

## ğŸ¤– Adicionando novos algoritmos

Os algoritmos sÃ£o encapsulados em classes e herdados de `BaseModel`.

### Como adicionar um novo algoritmo:

1. Crie um novo arquivo em `src/models/`, ex: `knn_model.py`
2. Implemente a classe `KNNModel`, com os mÃ©todos:
   - `train(self, X_train, y_train)`
   - `evaluate(self, X_test, y_test)` â†’ usando `evaluate_all()`
3. Use esse novo modelo em um experimento como qualquer outro

---
## ğŸ“‚ Adicionando novos datasets

O carregamento de datasets Ã© feito atravÃ©s da classe `DatasetFactory`, que seleciona dinamicamente a origem dos dados: `sklearn`, `csv`, ou futuras integraÃ§Ãµes.

### ğŸ’¡ Formas de carregar datasets:

- Via ```scikit-learn```: usando o ```SklearnDatasetLoader```

- Via `.csv`: usando o `CSVDatasetLoader`

### ğŸ› ï¸ Como adicionar um novo dataset:
### 1. Se a origem for sklearn:
- Registre o nome do dataset no enum `SklearnDatasetName`:
    ```python
    class SklearnDatasetName(Enum):
        IRIS = "iris"
        WINE = "wine"
    ```
- Use no experimento:
    ```python
    dataset = DatasetFactory.create(DatasetSourceType.SKLEARN, name=SklearnDatasetName.IRIS)
    ```

### 2. Se a origem for um arquivo CSV:

- Coloque o arquivo `.csv` em `datasets/<nome>/`, ex: `datasets/iris/iris.csv`

- Use o `CSVDatasetLoader` no experimento:
    ```python
    dataset = DatasetFactory.create(
        DatasetSourceType.CSV,
        path="datasets/wine/wine.csv",
        label_column="target"
    )
    ```

---

## ğŸ§  Adicionando novas tÃ©cnicas de inferÃªncia

TÃ©cnicas de inferÃªncia sÃ£o componentes modulares aplicadas aos dados de entrada (X), aos rÃ³tulos (y) ou aos parÃ¢metros (kwargs) dos modelos.

### Estrutura geral
Cada tÃ©cnica de inferÃªncia Ã© representada por uma classe que herda de `InferenceTransformation` (ou equivalente) e implementa o mÃ©todo `apply(...)`.

### âœ… 1. TÃ©cnicas aplicadas aos dados (X)
Cada tÃ©cnica de inferÃªncia Ã© representada por uma classe que herda de `InferenceTransformation` (ou equivalente) e implementa o mÃ©todo `apply(...)`.

Passos:
1. Crie um novo arquivo ou edite um existente em `src/inference/transformations/data/`.

2. Crie uma nova classe com o mÃ©todo:
```python
class MinhaTransformacao(InferenceTransformation):
    def apply(self, X):
        # sua lÃ³gica de transformaÃ§Ã£o
        return X_modificado
```
3. Registre a nova transformaÃ§Ã£o em `src/inference/engine/inference_engine.py`, adicionando uma verificaÃ§Ã£o no construtor e incluindo no pipeline.

4. Adicione um campo correspondente no `DatasetNoiseConfig` (com validaÃ§Ã£o Pydantic).

5. Utilize nos experimentos via `InferencePipeline`.

### âœ… 2. TÃ©cnicas aplicadas aos rÃ³tulos (y)

Passos:
1. Crie uma nova classe em `src/inference/transformations/label/`, herdando de LabelTransformation (ou base similar).

2. Implemente o mÃ©todo `apply(self, y)`.

3. Registre no `LabelInferenceEngine` (`src/inference/engine/label_runner.py`).

4. Configure no campo `label_noise_fraction` ou crie um novo campo em `DatasetNoiseConfig`.

### âœ… 3. TÃ©cnicas aplicadas aos parÃ¢metros dos modelos

Essas tÃ©cnicas sÃ£o tratadas por `SmartParameterPerturber`.

1. A lÃ³gica de perturbaÃ§Ã£o estÃ¡ em `src/inference/transformations/params/parameter_perturber.py`.

2. Para novas estratÃ©gias (ex: `replace_with_random`), adicione mÃ©todos internos na classe.

3. O ponto de entrada principal estÃ¡ em `src/inference/engine/param_runner.py` via a funÃ§Ã£o `apply_param_inference()`.

#### âš ï¸ As trÃªs categorias sÃ£o independentes, mas integradas por meio da InferencePipeline. VocÃª pode aplicar apenas uma, duas ou todas combinadas.
---

## ğŸ§° Suporte a InferÃªncia

Este framework suporta inferÃªncia em dois nÃ­veis:
## 1. InferÃªncia nos dados (data inference)

TÃ©cnicas que simulam ruÃ­do, falhas e distorÃ§Ãµes nos dados de entrada.

- RuÃ­do Aditivo: `GaussianNoise, FeatureSelectiveNoise`
- ReduÃ§Ã£o de PrecisÃ£o: `TruncateDecimals, CastToInt, Quantize`
- PerturbaÃ§Ã£o Estrutural: `ShuffleFeatures, ScaleFeatures, RemoveFeatures, FeatureSwap`
- CorrupÃ§Ã£o Direta: `ZeroOut, InsertNaN`
- Outliers: `InjectOutliers`
- DistraÃ§Ã£o SemÃ¢ntica: `AddDummyFeatures, DuplicateFeatures`
- Label Noise: `LabelNoise`

## 2. InferÃªncia em parÃ¢metros (parameter inference)
#### O `SmartParameterPerturber` realiza mutaÃ§Ãµes automÃ¡ticas e validadas em hiperparÃ¢metros dos modelos:
- AlteraÃ§Ãµes baseadas em tipo (`int`, `float`, `str`, `bool`)
- EstratÃ©gias como `add_noise`, `cast`, `drop`, `flip,` etc.
- Filtros por nome de parÃ¢metro e validaÃ§Ã£o automÃ¡tica do modelo
- GeraÃ§Ã£o de logs JSON para rastreamento de inferÃªncias aplicadas


## ğŸ§© EnumeraÃ§Ãµes e Tipagens do Framework
Essa seÃ§Ã£o serve como referÃªncia rÃ¡pida para desenvolvedores que forem integrar novos mÃ³dulos, criar loaders ou escrever experimentos

Local: `src/utils/types.py`
```python
class DatasetSourceType(Enum):
    SKLEARN = "sklearn"
    CSV = "csv"

class ReportMode(Enum):
    PRINT = "print"
    JSON = "json"

class SklearnDatasetName(Enum):
    IRIS = "iris"
    WINE = "wine"
    
class DatasetNoiseConfig(BaseModel):
    noise_level: Optional[float] = None  # Intensidade de ruÃ­do gaussiano
    truncate_decimals: Optional[int] = None  # NÃºmero de casas decimais
    quantize_bins: Optional[int] = None  # QuantizaÃ§Ã£o em N bins
    cast_to_int: Optional[bool] = None  # Converte para int
    shuffle_fraction: Optional[float] = None  # FracÌ§aÌƒo de colunas embaralhadas
    scale_range: Optional[Tuple[float, float]] = None  # Intervalo de escala (min, max)
    zero_out_fraction: Optional[float] = None  # FracÌ§aÌƒo de valores zerados
    insert_nan_fraction: Optional[float] = None  # FracÌ§aÌƒo de NaNs inseridos
    outlier_fraction: Optional[float] = None  # FracÌ§aÌƒo de outliers
    add_dummy_features: Optional[int] = None  # N novas features aleatÃ³rias
    duplicate_features: Optional[int] = None  # N features duplicadas
    feature_selective_noise: Optional[Tuple[float, List[int]]] = None  # (nÃ­vel, Ã­ndices)
    remove_features: Optional[List[int]] = None  # Ãndices a remover
    feature_swap: Optional[List[int]] = None  # Ãndices a trocar entre si
    label_noise_fraction: Optional[float] = None  # RuÃ­do nos rÃ³tulos
```
## ğŸ“š Objetivo
Avaliar a robustez e sensibilidade de algoritmos de IA em cenÃ¡rios realistas com:

- RuÃ­do nos dados
- Falhas de coleta ou sensores
- Valores fora do padrÃ£o esperado
- PerturbaÃ§Ãµes nos parÃ¢metros do modelo
---
