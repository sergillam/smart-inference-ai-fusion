# Smart Inference AI Fusion

Um framework modular e extensÃ­vel para experimentos de inferÃªncia sintÃ©tica e perturbaÃ§Ãµes controladas em algoritmos de InteligÃªncia Artificial (IA), com foco em robustez, variabilidade e testes de falhas em dados e parÃ¢metros.


## ğŸ“ Estrutura do Projeto
```
smart-inference-ai-fusion/
â”œâ”€â”€ main.py                      # Ponto de entrada principal para execuÃ§Ã£o dos experimentos
â”œâ”€â”€ makefile                     # Comandos automatizados para execuÃ§Ã£o, lint, testes etc.
â”œâ”€â”€ requirements.txt             # Lista de dependÃªncias do projeto
â”œâ”€â”€ datasets/                    # Bases de dados (ex: arquivos CSV do Titanic)
â”œâ”€â”€ docs/                        # DocumentaÃ§Ã£o adicional (ex: resumos de inferÃªncia)
â”œâ”€â”€ experiments/                 # Scripts de experimentos organizados por dataset
â”‚   â”œâ”€â”€ iris/
â”‚   â”œâ”€â”€ wine/
â”‚   â”œâ”€â”€ digits/
â”‚   â”œâ”€â”€ breast_cancer/
â”‚   â”œâ”€â”€ titanic/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                        # Logs de execuÃ§Ã£o e inferÃªncia (nÃ£o versionados)
â”œâ”€â”€ results/                     # Resultados dos experimentos e inferÃªncias (nÃ£o versionados)
â”œâ”€â”€ src/                         # CÃ³digo-fonte principal do framework
â”‚   â”œâ”€â”€ core/                    # Classes base para Experiment, Model e Dataset
â”‚   â”œâ”€â”€ datasets/                # Loaders de datasets (sklearn, csv) e fÃ¡bricas
â”‚   â”œâ”€â”€ inference/               # MÃ³dulo de inferÃªncia (pipelines, engines, transforms)
â”‚   â”‚   â”œâ”€â”€ engine/              # Orquestradores de inferÃªncia (InferenceEngine, LabelRunner, etc.)
â”‚   â”‚   â”œâ”€â”€ pipeline/            # Pipeline unificada que aplica todas as inferÃªncias
â”‚   â”‚   â”œâ”€â”€ transformations/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/            # TÃ©cnicas aplicadas aos dados de entrada (X)
â”‚   â”‚   â”‚   â”œâ”€â”€ label/           # TÃ©cnicas aplicadas aos rÃ³tulos (y)
â”‚   â”‚   â”‚   â””â”€â”€ params/          # EstratÃ©gias de perturbaÃ§Ã£o nos parÃ¢metros
â”‚   â”œâ”€â”€ models/                  # Modelos de IA implementados no framework
â”‚   â””â”€â”€ utils/                   # UtilitÃ¡rios, enums, mÃ©tricas, tipos
â””â”€â”€ tests/                       # Testes unitÃ¡rios do projeto
```

## ğŸš€ Guia de InstalaÃ§Ã£o e ExecuÃ§Ã£o

### Ambiente recomendado:
- Python 3.10
- Ambiente virtual (ex: `venv` ou `conda`)

### InstalaÃ§Ã£o:
#### Linux / MacOS:
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

#### Windows:
```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### Uso do Makefile (recomendado):
O projeto possui um Makefile com comandos Ãºteis para rodar experimentos, checar estilo, rodar testes e instalar dependÃªncias.

Use os comandos abaixo para simplificar o fluxo de trabalho:
- Executa o pipeline principal (main.py)
    ```bash
    make run
    ```
- Lint (checa estilo e boas prÃ¡ticas com pylint)
    ```bash
    make lint
    ```
- Checa docstrings no padrÃ£o Google (pydocstyle)
    ```bash
    make style
    ```
- Roda os dois acima juntos (make lint e make style)
    ```bash
    make check
    ```
- Executa TODOS os testes unitÃ¡rios
    ```bash
    make test
    ```
- Instala as dependÃªncias do projeto
    ```bash
    make requirements
    ```
- Executa tudo (lint, style, test, run)
    ```bash
    make all
    ```
- Disponibiliza todos os comandos disponÃ­veis e exemplos avanÃ§ados
    ```bash
    make help
    ```
### Executando experimentos especÃ­ficos:
Para rodar um experimento individual (arquivo ou diretÃ³rio):
```bash
make experiment EXP=experiments/iris/knn_iris.py
make experiment EXP=experiments/wine/
```

### ExecuÃ§Ã£o manual (opcional):
```bash
PYTHONPATH=src python main.py
```

## ğŸ§ª Adicionando novos experimentos

Um experimento representa a aplicaÃ§Ã£o de um algoritmo a um dataset, com ou sem inferÃªncia aplicada (nos dados e/ou nos parÃ¢metros).


### âœ… 1. Escolha e carregue o **dataset**

Utilize a `DatasetFactory` para criar dinamicamente o carregador com o dataset na origem (`sklearn`, `csv`, etc):

```python
from datasets.factory import DatasetFactory
from utils.types import DatasetSourceType, SklearnDatasetName

# Exemplo: carregar o dataset Iris do sklearn
dataset = DatasetFactory.create(
    source_type=DatasetSourceType.SKLEARN,
    name=SklearnDatasetName.IRIS
)
```

Para dataset externos (ex: `.csv`), troque o tipo e informe o caminho:
```python
dataset = DatasetFactory.create(
    source_type=DatasetSourceType.CSV,
    path="datasets/wine/wine.csv",
    label_column="target"
)

```
Como obter os splits:

Obtenha os dados jÃ¡ separados em treino/teste (80% treino, 20% teste)
```python
X_train, X_test, y_train, y_test = dataset.load_split(test_size=0.2)
```
ğŸ’¡ Dica: Consulte a docstring da `DatasetFactory` para outros tipos suportados, como outros datasets do sklearn, arquivos csv customizados, etc.

### âœ… 2. Defina o modelo (algoritmo de IA):

Importe o modelo desejado e configure os parÃ¢metros base:

```python
from models.knn_model import KNNModel
base_params = {"n_neighbors": 3, "weights": "uniform"}
model = KNNModel(base_params)
```
â„¹ï¸ ObservaÃ§Ã£o: O framework possui modelos prontos para KNN, SVM, Decision Tree, Perceptron, GaussianNB e outros. Consulte o diretÃ³rio `src/models/` para ver todos os disponÃ­veis.

â¡ï¸ PrÃ³ximo passo: Configure sua pipeline de inferÃªncia para aplicar perturbaÃ§Ãµes nos dados, rÃ³tulos ou parÃ¢metros do modelo (veja o Passo 3).

###  âœ… 3. Adicione inferÃªncia com o `InferencePipeline`

#### âœ… 3.1 InferÃªncia nos parÃ¢metros
- Informe as configuraÃ§Ãµes separadas para dados `DataNoiseConfig`, rÃ³tulos `LabelNoiseConfig` e parÃ¢metros do modelo `ParameterNoiseConfig`.
Essas configs sÃ£o validadas por Pydantic e cada uma ativa diferentes tÃ©cnicas:

    ```python
    from utils.types import DataNoiseConfig, LabelNoiseConfig, ParameterNoiseConfig

    data_noise_config = DataNoiseConfig(
        noise_level=0.2,
        truncate_decimals=1,
        quantize_bins=5,
        cast_to_int=False,
        shuffle_fraction=0.1,
        scale_range=(0.8, 1.2),
        zero_out_fraction=0.05,
        insert_nan_fraction=0.05,
        outlier_fraction=0.05,
        add_dummy_features=2,
        duplicate_features=2,
        feature_selective_noise=(0.3, [0, 2]),
        remove_features=[1, 3],
        feature_swap=[0, 2],
        conditional_noise=(0, 5.0, 0.2),
        random_missing_block_fraction=0.1,
        distribution_shift_fraction=0.1,
        cluster_swap_fraction=0.1,
        group_outlier_cluster_fraction=0.1,
        temporal_drift_std=0.5,
    )

    label_noise_config = LabelNoiseConfig(
        label_noise_fraction=0.1,
        flip_near_border_fraction=0.1,
        confusion_matrix_noise_level=0.1,
        partial_label_fraction=0.1,
        swap_within_class_fraction=0.1,
    )

    param_noise_config = ParameterNoiseConfig(
        integer_noise=True,
        boolean_flip=True,
        string_mutator=True,
        semantic_mutation=True,
        scale_hyper=True,
        cross_dependency=True,
        random_from_space=True,
        bounded_numeric=True,
        type_cast_perturbation=True,
        enum_boundary_shift=True,
    )
    ```

#### âœ… 3.2 Instancie a pipeline de inferÃªncia
- Instancie o pipeline passando as configs desejadas (todas opcionais):
    ```python
    from inference.pipeline.inference_pipeline import InferencePipeline

    pipeline = InferencePipeline(
        data_noise_config=data_noise_config,
        label_noise_config=label_noise_config,
        X_train=X_train,  # X_train Ã© necessÃ¡rio para algumas tÃ©cnicas de rÃ³tulo
    )
    ```

#### âœ… 3.3 Aplique as perturbaÃ§Ãµes
- Dados (X):
    ```python
    X_train_pert, X_test_pert = pipeline.apply_data_inference(X_train, X_test)
    ```
- RÃ³tulos (y):
    ```python
    y_train_pert, y_test_pert = pipeline.apply_label_inference(
        y_train, y_test,
        model=model,             # obrigatÃ³rio para algumas tÃ©cnicas (ex: flip_near_border)
        X_train=X_train_pert,    # passe os dados jÃ¡ perturbados, se aplicÃ¡vel
        X_test=X_test_pert
    )
    ```
- ParÃ¢metros (opcional, para perturbar hiperparÃ¢metros):
    ```python
    from models.gaussian_model import GaussianNBModel

    model, param_log = pipeline.apply_param_inference(
        model_class=GaussianNBModel,
        base_params={"var_smoothing": 1e-9}
    )
    ```
##### Obs:
- Passe apenas as configs de interesse. Se nÃ£o quiser inferÃªncia em algum aspecto, omita o argumento (por exemplo, `InferencePipeline(data_noise_config=data_noise_config))`.

- Consulte os exemplos em `experiments/` para fluxos completos.

### âœ… 4. Execute o experimento:

- Monte o experimento com ou sem inferÃªncia:
    ```python
    from core.experiment import Experiment

    experiment = Experiment(model, dataset)
    metrics = experiment.run(X_train, X_test, y_train, y_test)
    ```

### âœ… 5. Reporte os resultados:
```python
from utils.report import report_data, ReportMode

report_data(metrics, mode=ReportMode.PRINT)
report_data(param_log, mode=ReportMode.JSON, file_path="results/knn_param_log.json")
```

### âœ… 6. Integre ao sistema de execuÃ§Ã£o:
- Crie funÃ§Ãµes pÃºblicas de entrada para seus experimentos, seguindo o padrÃ£o abaixo:
    ```python
    # experiments/<dataset>/<seu_experimento>.py

    def run_<algoritmo>_without_inference():
        # ConfiguraÃ§Ã£o e execuÃ§Ã£o SEM inferÃªncia
        pass

    def run_<algoritmo>_with_inference():
        # ConfiguraÃ§Ã£o e execuÃ§Ã£o COM inferÃªncia
        pass

    def run():
        """Executa todas as variantes deste experimento."""
        run_<algoritmo>_without_inference()
        run_<algoritmo>_with_inference()
    ```
- No arquivo `experiments/<dataset>/__init__.py`, importe e chame os experimentos desse dataset:
    ```python
    # experiments/<dataset>/__init__.py

    from .<seu_experimento> import run as run_<algoritmo>

    def run_all():
        print("=== Executando todos os experimentos para <dataset> ===")
        run_<algoritmo>()  # Adicione mais funÃ§Ãµes se tiver outros experimentos
        print("=== Experimentos concluÃ­dos ===")
    ```
- Inclua no `__init__.py` da pasta `experiments/<dataset>/`

---

## ğŸ¤– Adicionando novos algoritmos

Os algoritmos sÃ£o encapsulados em classes e herdados de `BaseModel`.

### Como adicionar um novo algoritmo:

1. Crie um novo arquivo em `src/models/`, ex: `knn_model.py`
2. Implemente a classe `KNNModel`, com os mÃ©todos:
   - `train(self, X_train, y_train)`
   - `evaluate(self, X_test, y_test)` â†’ usando `evaluate_all()`
3. Use esse novo modelo em um experimento como qualquer outro

---
## ğŸ“‚ Adicionando novos datasets

O carregamento de datasets Ã© feito atravÃ©s da classe `DatasetFactory`, que seleciona dinamicamente a origem dos dados: `sklearn`, `csv`, ou futuras integraÃ§Ãµes.

### ğŸ’¡ Formas de carregar datasets:

- Via ```scikit-learn```: usando o ```SklearnDatasetLoader```

- Via `.csv`: usando o `CSVDatasetLoader`

### ğŸ› ï¸ Como adicionar um novo dataset:
### 1. Se a origem for sklearn:
- Registre o nome do dataset no enum `SklearnDatasetName`:
    ```python
    class SklearnDatasetName(Enum):
        IRIS = "iris"
        WINE = "wine"
    ```
- Use no experimento:
    ```python
    dataset = DatasetFactory.create(DatasetSourceType.SKLEARN, name=SklearnDatasetName.IRIS)
    ```

### 2. Se a origem for um arquivo CSV:

- Coloque o arquivo `.csv` em `datasets/<nome>/`, ex: `datasets/iris/iris.csv`

- Use o `CSVDatasetLoader` no experimento:
    ```python
    dataset = DatasetFactory.create(
        DatasetSourceType.CSV,
        path="datasets/wine/wine.csv",
        label_column="target"
    )
    ```

---

## ğŸ§  Adicionando novas tÃ©cnicas de inferÃªncia

TÃ©cnicas de inferÃªncia sÃ£o componentes modulares aplicadas aos dados de entrada (X), aos rÃ³tulos (y) ou aos parÃ¢metros (kwargs) dos modelos.

### Estrutura geral
Cada tÃ©cnica de inferÃªncia Ã© representada por uma classe que herda de `InferenceTransformation`, `LabelTransformation` ou `ParameterTransformation`, e implementa o mÃ©todo `apply(...)`.

### âœ… 1. TÃ©cnicas aplicadas aos dados (X)

Passos:
1. Crie um novo arquivo ou edite um existente em `src/inference/transformations/data/`.

2. Implemente a nova classe herdando de `InferenceTransformation` e o mÃ©todo `apply(self, X)`.
    ```python
    class MinhaTransformacao(InferenceTransformation):
        def apply(self, X):
            # Sua lÃ³gica aqui
            return X_modificado
    ```
3. Registre a nova transformaÃ§Ã£o no pipeline em `src/inference/engine/inference_engine.py`, adicionando uma verificaÃ§Ã£o no construtor e incluindo no pipeline.

4. Adicione um campo correspondente (se desejar configurÃ¡vel) no `DataNoiseConfig` (`src/utils/types.py`).

5. Utilize nos experimentos via `InferencePipeline`.

### âœ… 2. TÃ©cnicas aplicadas aos rÃ³tulos (y)

Passos:
1. Crie uma nova classe em `src/inference/transformations/label/`, herdando de `LabelTransformation` (ou base similar).

2. Implemente o mÃ©todo `apply(self, y)`  (ou `apply(self, y, X=None, model=None`) se precisar).

3. Registre a tÃ©cnica no pipeline em (`src/inference/engine/label_runner.py`).

4. Configure no campo adequado em `LabelNoiseConfig` (em `src/utils/types.py`).

### âœ… 3. TÃ©cnicas aplicadas aos parÃ¢metros dos modelos

Essas tÃ©cnicas sÃ£o tratadas por `SmartParameterPerturber`.

1. Crie uma nova classe de transformaÃ§Ã£o em `src/inference/transformations/params/` herdando de `ParameterTransformation` e implementando o mÃ©todo `apply(self, params)`.

2. Importe e registre a nova tÃ©cnica no pipeline em `src/inference/engine/param_runner.py` (na lista de tÃ©cnicas disponÃ­veis).

3. Se necessÃ¡rio, adicione uma flag de configuraÃ§Ã£o em `ParameterNoiseConfig` (`src/utils/types.py`).

4. O ponto de entrada para orquestraÃ§Ã£o Ã© o mÃ©todo `apply_param_inference()` da pipeline.

#### âš ï¸ As trÃªs categorias sÃ£o independentes, mas integradas por meio da `InferencePipeline`. VocÃª pode aplicar apenas uma, duas ou todas combinadas nos seus experimentos.
---

## ğŸ§¬ Suporte a InferÃªncia
Este framework suporta inferÃªncia sintÃ©tica em mÃºltiplos nÃ­veis, possibilitando testes de robustez em diferentes etapas do pipeline de IA:
## 1. InferÃªncia nos dados (data inference)

#### TÃ©cnicas para simular ruÃ­do, falhas e distorÃ§Ãµes nos dados de entrada (`X`) :

- **RuÃ­do Aditivo**: `GaussianNoise, FeatureSelectiveNoise`
- **ReduÃ§Ã£o de PrecisÃ£o**: `TruncateDecimals, CastToInt, Quantize`
- **PerturbaÃ§Ã£o Estrutural**: `ShuffleFeatures, ScaleFeatures, RemoveFeatures, FeatureSwap`
- **CorrupÃ§Ã£o Direta**: `ZeroOut, InsertNaN`
- **Outliers**: `InjectOutliers`
- **DistraÃ§Ã£o SemÃ¢ntica**: `AddDummyFeatures, DuplicateFeatures`
- **PerturbaÃ§Ãµes tabulares avanÃ§adas**: `RandomMissingBlock`, `DistributionShiftMixing`, `ClusterSwap`, `GroupOutlierInjection`, `TemporalDriftInjection`.

## 2. InferÃªncia nos rÃ³tulos (label inference)
#### TÃ©cnicas para simular erros e ambiguidade nos rÃ³tulos (`y`):
- **RuÃ­do aleatÃ³rio**: `RandomLabelNoise`
- **RuÃ­do guiado por matriz de confusÃ£o:** `LabelConfusionMatrixNoise`
- **Flip near border** (baixa confianÃ§a do modelo): `LabelFlipNearBorder`
- **Ambiguidade parcial**: `PartialLabelNoise`
- **Troca de rÃ³tulos dentro de classes**: `LabelSwapWithinClass`

## 3. InferÃªncia em parÃ¢metros (parameter inference)
#### O `SmartParameterPerturber` realiza mutaÃ§Ãµes automÃ¡ticas e validadas em hiperparÃ¢metros dos modelos, incluindo:
- **AlteraÃ§Ãµes baseadas em tipo**: (`int`, `float`, `str`, `bool`)
- **EstratÃ©gias**: `add_noise`, `cast`, `drop`, `flip`, entre outras.
- **Filtros por nome de parÃ¢metro e validaÃ§Ã£o automÃ¡tica do modelo**
- **GeraÃ§Ã£o de logs JSON para rastreamento das inferÃªncias aplicadas**.

#### âš¡ Nota: As trÃªs categorias sÃ£o independentes, mas integradas via a `InferencePipeline`. VocÃª pode aplicar apenas uma, duas ou todas as inferÃªncias combinadas em seus experimentos.

## ğŸ§© EnumeraÃ§Ãµes e Tipagens do Framework
As definiÃ§Ãµes que padronizam origem de dados, nomes de datasets, modos de relatÃ³rio e configs de perturbaÃ§Ã£o ficam em  `src/utils/types.py`

- **DatasetSourceType** â†’ origem dos dados: `SKLEARN`, `CSV`.
- **SklearnDatasetName** â†’ conjuntos suportados: `IRIS`, `WINE`, `BREAST_CANCER`, `DIGITS`.
- **CSVDatasetName** â†’ atalhos de CSV (ex.: `TITANIC`) com propriedade `.path`.
- **ReportMode** â†’ destino do output: `PRINT` (console), `JSON_LOG` (`logs/`), `JSON_RESULT` (`results/`).

#### Configs de perturbaÃ§Ã£o (Pydantic):
- **DataNoiseConfig** â†’ perturbaÃ§Ãµes em X (dados):
    ruÃ­do/precisÃ£o: `noise_level`, `truncate_decimals`, `quantize_bins`, `cast_to_int`.
    - estrutura/escala: `shuffle_fraction`, `scale_range`, `remove_features`, `feature_swap`.
    - corrupÃ§Ã£o/outliers/missing: `zero_out_fraction`, `insert_nan_fraction`, `outlier_fraction`
    - avanÃ§adas tabulares: `feature_selective_noise`, `conditional_noise`,
        `random_missing_block_fraction`, `distribution_shift_fraction`,
        `cluster_swap_fraction`, `group_outlier_cluster_fraction`, `temporal_drift_std`
    - distraÃ§Ãµes: `add_dummy_features`, `duplicate_features`

    noise_level: # Intensidade de ruÃ­do gaussiano
    truncate_decimals: # NÃºmero de casas decimais
    quantize_bins: # QuantizaÃ§Ã£o em N bins
    cast_to_int: # Converte para int
    shuffle_fraction: # FracÌ§aÌƒo de colunas embaralhadas
    scale_range:  # Intervalo de escala (min, max)
    zero_out_fraction: # FracÌ§aÌƒo de valores zerados
    insert_nan_fraction: # FracÌ§aÌƒo de NaNs inseridos
    outlier_fraction: # FracÌ§aÌƒo de outliers
    add_dummy_features: # N novas features aleatÃ³rias
    duplicate_features: # N features duplicadas
    feature_selective_noise: # (nÃ­vel, Ã­ndices)
    remove_features: # Ãndices a remover
    feature_swap: # Ãndices a trocar entre si
    label_noise_fraction: # RuÃ­do nos rÃ³tulos

- **LabelNoiseConfig** â†’ perturbaÃ§Ãµes em **y** (rÃ³tulos):  
  `label_noise_fraction`, `flip_near_border_fraction`, `confusion_matrix_noise_level`,
  `partial_label_fraction`, `swap_within_class_fraction`.

- **ParameterNoiseConfig** â†’ estratÃ©gias para hiperparÃ¢metros:
   `integer_noise`, `boolean_flip`, `string_mutator`, `semantic_mutation`, `scale_hyper`, `cross_dependency`, `random_from_space`, `bounded_numeric`, `type_cast_perturbation`, `enum_boundary_shift`.

## ğŸ“š Objetivo

Avaliar a robustez e a sensibilidade de modelos de IA sob **perturbaÃ§Ãµes controladas** em dados, rÃ³tulos e hiperparÃ¢metros, simulando:

- ruÃ­do e perdas de precisÃ£o;  
- falhas de coleta/sensores e valores ausentes;  
- outliers e mudanÃ§as de distribuiÃ§Ã£o;  
- erros de anotaÃ§Ã£o e variaÃ§Ãµes de configuraÃ§Ã£o do modelo.  

---

## ğŸ“„ PublicaÃ§Ã£o

**Sergillam Barroso Oliveira**, **Eddie B de Lima Filho**, **Lucas Cordeiro**.  
*Modular Architecture for Robustness Assessment in AI Using Smart Inference*.  
In: **2025 IEEE 14th Global Conference on Consumer Electronics (GCCE)** â€” Track OS-DSC, apresentaÃ§Ã£o oral (*Student Paper*).  
EDAS ID: **1571156254**.  

### ğŸ“Œ Como citar
```bibtex
@inproceedings{oliveira2025modular,
  author    = {Sergillam Barroso Oliveira and Eddie B de Lima Filho and Lucas Cordeiro},
  title     = {Modular Architecture for Robustness Assessment in AI Using Smart Inference},
  booktitle = {Proceedings of the 2025 IEEE 14th Global Conference on Consumer Electronics (GCCE)},
  year      = {2025},
  month     = sep,
  publisher = {IEEE},
  note      = {Track: OS-DSC (Oral, Student Paper), EDAS ID: 1571156254}
}
```
---
