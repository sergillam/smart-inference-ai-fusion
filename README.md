# Smart Inference AI Fusion

Um framework modular e extens√≠vel para experimentos de infer√™ncia sint√©tica e perturba√ß√µes controladas em algoritmos de Intelig√™ncia Artificial (IA), com foco em robustez, variabilidade e testes de falhas em dados e par√¢metros.


## üìÅ Estrutura do Projeto
```
‚îú‚îÄ‚îÄ pyproject.toml               # Arquivo de configura√ß√£o que gerencia depend√™ncias e build do projeto
‚îú‚îÄ‚îÄ makefile                     # Comandos automatizados para execu√ß√£o, lint, testes etc.
‚îú‚îÄ‚îÄ README.md                    # Documenta√ß√£o principal do projeto
‚îú‚îÄ‚îÄ datasets/                    # Cont√©m os datasets n√£o oriundos do scikit-learn (ex: arquivos .csv)
‚îú‚îÄ‚îÄ docs/                        # Documenta√ß√£o adicional e resumos
‚îú‚îÄ‚îÄ logs/                        # Logs de execu√ß√£o e infer√™ncia
‚îú‚îÄ‚îÄ results/                     # Resultados dos experimentos e infer√™ncias
‚îú‚îÄ‚îÄ scripts/                     # Cont√©m scripts utilizados para automa√ß√£o de configura√ß√£o;
‚îú‚îÄ‚îÄ smart_inference_ai_fusion/   # C√≥digo-fonte principal do framework
‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Classes base para Experimento, Modelo e Dataset
‚îÇ   ‚îú‚îÄ‚îÄ datasets/                # M√≥dulos para carregar datasets (de arquivos CSV, scikit-learn etc.)
‚îÇ   ‚îú‚îÄ‚îÄ experiments/             # Scripts de experimentos, agora parte do pacote, com um `run.py` orquestrador
‚îÇ   ‚îú‚îÄ‚îÄ inference/               # M√≥dulo central de infer√™ncia de ru√≠dos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine/              # Motores que orquestram a aplica√ß√£o das perturba√ß√µes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline/            # Pipeline que integra e aplica as transforma√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformations/     # L√≥gicas de perturba√ß√£o, separadas por alvo:
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ data/            # T√©cnicas aplicadas aos dados de entrada (X)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ label/           # T√©cnicas aplicadas aos r√≥tulos (y)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ params/          # Estrat√©gias de perturba√ß√£o nos hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Wrappers de modelos (BaseModel-compat√≠veis)
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Fun√ß√µes utilit√°rias, tipos, m√©tricas e relat√≥rios
‚îî‚îÄ‚îÄ tests/                       # Testes unit√°rios do framework
```

## üöÄ Guia de Instala√ß√£o e Execu√ß√£o
### Este guia assume que voc√™ est√° em um ambiente `Linux` ou `MacOS`.
#### **Pr√©-requisitos**:
- `Git`
- `Python 3.10`
- `Make` para usar os comandos automatizados

#### **Instala√ß√£o (M√©todo Recomendado: `make`)**

O `Makefile` automatiza todo o processo de configura√ß√£o. Voc√™ s√≥ precisa de um comando.
1. **Clone o reposit√≥rio:**
    ```bash
    git clone git@github.com:sergillam/smart-inference-ai-fusion.git
    cd smart-inference-ai-fusion
    ```

2. **Instale as depend√™ncias:**
    
    - **Para desenvolver no projeto (Recomendado):**
    
        Este comando cria o ambiente virtual, instala todas as depend√™ncias (de execu√ß√£o, testes, linting, etc.) e o pacote em modo edit√°vel.
        ```bash
        make install-dev
        ```
    
    - **Apenas para executar os experimentos:**
    

        Este comando faz uma instala√ß√£o m√≠nima, apenas com as depend√™ncias de execu√ß√£o.
        ```bash
        make install
        ```

    - **Nota: Voc√™ n√£o precisa criar ou ativar o ambiente virtual (venv) manualmente. Os comandos make cuidam de tudo para voc√™.**

#### **Executando os Experimentos**

Use `make run` para executar os scripts. A vari√°vel `EXP` define o alvo.

1. **Executar Todos os Experimentos**
    
    Roda o orquestrador principal que executa todos os scripts de experimento.
    ```bash
    make run
    ```

2. **Executar um Pacote de Experimentos**
    
    Roda todos os experimentos de um diret√≥rio espec√≠fico.
    ```bash
    make run EXP=smart_inference_ai_fusion.experiments.name_data_set
    ```

3. **Executar um √önico Experimentos**
    
    Roda um √∫nico arquivo de experimento.
    ```bash
    make run EXP=smart_inference_ai_fusion.experiments.name_data_set.name_experiments
    ```

4. **Passando Argumentos para os Scripts**
    
    Use a vari√°vel `ARGS` para passar argumentos customizados para seus scripts.
    ```bash
    make run EXP=<seu_alvo> ARGS="--seed 42 --outro_parametro valor"
    ```

5. **Executar em Modo Debug**
    
    Para uma sa√≠da de log mais detalhada.
    ```bash
    make debug
    ```

#### **Workflow de Desenvolvimento**

O `Makefile` inclui v√°rios comandos para garantir a qualidade e a manuten√ß√£o do c√≥digo.

- `make check`: Roda todas as verifica√ß√µes de qualidade (formata√ß√£o, linting e estilo de docstrings).
- `make format`: Formata o c√≥digo automaticamente.
- `make test`: Roda a su√≠te de testes unit√°rios.
- `make clean-outputs`: Limpa as pastas de `logs` e `results` (√∫til para garantir uma execu√ß√£o limpa).
- `make help`: Lista todos os comandos dispon√≠veis e o que eles fazem.

#### **Instala√ß√£o Manual (Alternativa)**
Para usu√°rios de `Windows` ou que n√£o desejam usar `make`.
```bash
# 1. Clone o reposit√≥rio e entre na pasta

git clone git@github.com:sergillam/smart-inference-ai-fusion.git
cd smart-inference-ai_fusion

# 2. Crie e ative o ambiente virtual
# No Windows:
python -m venv .venv
.\.venv\Scripts\activate

# No Linux / MacOS:
# python3.10 -m venv .venv
# source .venv/bin/activate

# 3. Instale o projeto e suas depend√™ncias
# O comando abaixo l√™ o `pyproject.toml` e instala tudo
pip install -e .[dev]

# Para instala√ß√£o m√≠nima (sem ferramentas de dev), use:
# pip install -e .
```

## üß™ Adicionando novos experimentos

Um experimento representa a aplica√ß√£o de um algoritmo a um dataset, com ou sem infer√™ncia aplicada (nos dados e/ou nos par√¢metros).


### ‚úÖ 1. Escolha e carregue o **dataset**

Utilize a `DatasetFactory` para criar dinamicamente o carregador com o dataset na origem (`sklearn`, `csv`, etc):

```python
from datasets.factory import DatasetFactory
from utils.types import DatasetSourceType, SklearnDatasetName

# Exemplo: carregar o dataset Iris do sklearn
dataset = DatasetFactory.create(
    source_type=DatasetSourceType.SKLEARN,
    name=SklearnDatasetName.IRIS
)
```

Para dataset externos (ex: `.csv`), troque o tipo e informe o caminho:
```python
dataset = DatasetFactory.create(
    source_type=DatasetSourceType.CSV,
    path="datasets/wine/wine.csv",
    label_column="target"
)

```
Como obter os splits:

Obtenha os dados j√° separados em treino/teste (80% treino, 20% teste)
```python
X_train, X_test, y_train, y_test = dataset.load_split(test_size=0.2)
```
üí° Dica: Consulte a docstring da `DatasetFactory` para outros tipos suportados, como outros datasets do sklearn, arquivos csv customizados, etc.

### ‚úÖ 2. Defina o modelo (algoritmo de IA):

Importe o modelo desejado e configure os par√¢metros base:

```python
from models.knn_model import KNNModel
base_params = {"n_neighbors": 3, "weights": "uniform"}
model = KNNModel(base_params)
```
‚ÑπÔ∏è Observa√ß√£o: O framework possui modelos prontos para KNN, SVM, Decision Tree, Perceptron, GaussianNB e outros. Consulte o diret√≥rio `src/models/` para ver todos os dispon√≠veis.

‚û°Ô∏è Pr√≥ximo passo: Configure sua pipeline de infer√™ncia para aplicar perturba√ß√µes nos dados, r√≥tulos ou par√¢metros do modelo (veja o Passo 3).

###  ‚úÖ 3. Adicione infer√™ncia com o `InferencePipeline`

#### ‚úÖ 3.1 Infer√™ncia nos par√¢metros
- Informe as configura√ß√µes separadas para dados `DataNoiseConfig`, r√≥tulos `LabelNoiseConfig` e par√¢metros do modelo `ParameterNoiseConfig`.
Essas configs s√£o validadas por Pydantic e cada uma ativa diferentes t√©cnicas:

    ```python
    from utils.types import DataNoiseConfig, LabelNoiseConfig, ParameterNoiseConfig

    data_noise_config = DataNoiseConfig(
        noise_level=0.2,
        truncate_decimals=1,
        quantize_bins=5,
        cast_to_int=False,
        shuffle_fraction=0.1,
        scale_range=(0.8, 1.2),
        zero_out_fraction=0.05,
        insert_nan_fraction=0.05,
        outlier_fraction=0.05,
        add_dummy_features=2,
        duplicate_features=2,
        feature_selective_noise=(0.3, [0, 2]),
        remove_features=[1, 3],
        feature_swap=[0, 2],
        conditional_noise=(0, 5.0, 0.2),
        random_missing_block_fraction=0.1,
        distribution_shift_fraction=0.1,
        cluster_swap_fraction=0.1,
        group_outlier_cluster_fraction=0.1,
        temporal_drift_std=0.5,
    )

    label_noise_config = LabelNoiseConfig(
        label_noise_fraction=0.1,
        flip_near_border_fraction=0.1,
        confusion_matrix_noise_level=0.1,
        partial_label_fraction=0.1,
        swap_within_class_fraction=0.1,
    )

    param_noise_config = ParameterNoiseConfig(
        integer_noise=True,
        boolean_flip=True,
        string_mutator=True,
        semantic_mutation=True,
        scale_hyper=True,
        cross_dependency=True,
        random_from_space=True,
        bounded_numeric=True,
        type_cast_perturbation=True,
        enum_boundary_shift=True,
    )
    ```

#### ‚úÖ 3.2 Instancie a pipeline de infer√™ncia
- Instancie o pipeline passando as configs desejadas (todas opcionais):
    ```python
    from inference.pipeline.inference_pipeline import InferencePipeline

    pipeline = InferencePipeline(
        data_noise_config=data_noise_config,
        label_noise_config=label_noise_config,
        X_train=X_train,  # X_train √© necess√°rio para algumas t√©cnicas de r√≥tulo
    )
    ```

#### ‚úÖ 3.3 Aplique as perturba√ß√µes
- Dados (X):
    ```python
    X_train_pert, X_test_pert = pipeline.apply_data_inference(X_train, X_test)
    ```
- R√≥tulos (y):
    ```python
    y_train_pert, y_test_pert = pipeline.apply_label_inference(
        y_train, y_test,
        model=model,             # obrigat√≥rio para algumas t√©cnicas (ex: flip_near_border)
        X_train=X_train_pert,    # passe os dados j√° perturbados, se aplic√°vel
        X_test=X_test_pert
    )
    ```
- Par√¢metros (opcional, para perturbar hiperpar√¢metros):
    ```python
    from models.gaussian_model import GaussianNBModel

    model, param_log = pipeline.apply_param_inference(
        model_class=GaussianNBModel,
        base_params={"var_smoothing": 1e-9}
    )
    ```
##### Obs:
- Passe apenas as configs de interesse. Se n√£o quiser infer√™ncia em algum aspecto, omita o argumento (por exemplo, `InferencePipeline(data_noise_config=data_noise_config))`.

- Consulte os exemplos em `experiments/` para fluxos completos.

### ‚úÖ 4. Execute o experimento:

- Monte o experimento com ou sem infer√™ncia:
    ```python
    from core.experiment import Experiment

    experiment = Experiment(model, dataset)
    metrics = experiment.run(X_train, X_test, y_train, y_test)
    ```

### ‚úÖ 5. Reporte os resultados:
```python
from utils.report import report_data, ReportMode

report_data(metrics, mode=ReportMode.PRINT)
report_data(param_log, mode=ReportMode.JSON, file_path="results/knn_param_log.json")
```

### ‚úÖ 6. Integre ao sistema de execu√ß√£o:
- Crie fun√ß√µes p√∫blicas de entrada para seus experimentos, seguindo o padr√£o abaixo:
    ```python
    # experiments/<dataset>/<seu_experimento>.py

    def run_<algoritmo>_without_inference():
        # Configura√ß√£o e execu√ß√£o SEM infer√™ncia
        pass

    def run_<algoritmo>_with_inference():
        # Configura√ß√£o e execu√ß√£o COM infer√™ncia
        pass

    def run():
        """Executa todas as variantes deste experimento."""
        run_<algoritmo>_without_inference()
        run_<algoritmo>_with_inference()
    ```
- No arquivo `experiments/<dataset>/__init__.py`, importe e chame os experimentos desse dataset:
    ```python
    # experiments/<dataset>/__init__.py

    from .<seu_experimento> import run as run_<algoritmo>

    def run_all():
        print("=== Executando todos os experimentos para <dataset> ===")
        run_<algoritmo>()  # Adicione mais fun√ß√µes se tiver outros experimentos
        print("=== Experimentos conclu√≠dos ===")
    ```
- Inclua no `__init__.py` da pasta `experiments/<dataset>/`

---

## ü§ñ Adicionando novos algoritmos

Os algoritmos s√£o encapsulados em classes e herdados de `BaseModel`.

### Como adicionar um novo algoritmo:

1. Crie um novo arquivo em `src/models/`, ex: `knn_model.py`
2. Implemente a classe `KNNModel`, com os m√©todos:
   - `train(self, X_train, y_train)`
   - `evaluate(self, X_test, y_test)` ‚Üí usando `evaluate_all()`
3. Use esse novo modelo em um experimento como qualquer outro

---
## üìÇ Adicionando novos datasets

O carregamento de datasets √© feito atrav√©s da classe `DatasetFactory`, que seleciona dinamicamente a origem dos dados: `sklearn`, `csv`, ou futuras integra√ß√µes.

### üí° Formas de carregar datasets:

- Via ```scikit-learn```: usando o ```SklearnDatasetLoader```

- Via `.csv`: usando o `CSVDatasetLoader`

### üõ†Ô∏è Como adicionar um novo dataset:
### 1. Se a origem for sklearn:
- Registre o nome do dataset no enum `SklearnDatasetName`:
    ```python
    class SklearnDatasetName(Enum):
        IRIS = "iris"
        WINE = "wine"
    ```
- Use no experimento:
    ```python
    dataset = DatasetFactory.create(DatasetSourceType.SKLEARN, name=SklearnDatasetName.IRIS)
    ```

### 2. Se a origem for um arquivo CSV:

- Coloque o arquivo `.csv` em `datasets/<nome>/`, ex: `datasets/iris/iris.csv`

- Use o `CSVDatasetLoader` no experimento:
    ```python
    dataset = DatasetFactory.create(
        DatasetSourceType.CSV,
        path="datasets/wine/wine.csv",
        label_column="target"
    )
    ```

---

## üß† Adicionando novas t√©cnicas de infer√™ncia

T√©cnicas de infer√™ncia s√£o componentes modulares aplicadas aos dados de entrada (X), aos r√≥tulos (y) ou aos par√¢metros (kwargs) dos modelos.

### Estrutura geral
Cada t√©cnica de infer√™ncia √© representada por uma classe que herda de `InferenceTransformation`, `LabelTransformation` ou `ParameterTransformation`, e implementa o m√©todo `apply(...)`.

### ‚úÖ 1. T√©cnicas aplicadas aos dados (X)

Passos:
1. Crie um novo arquivo ou edite um existente em `src/inference/transformations/data/`.

2. Implemente a nova classe herdando de `InferenceTransformation` e o m√©todo `apply(self, X)`.
    ```python
    class MinhaTransformacao(InferenceTransformation):
        def apply(self, X):
            # Sua l√≥gica aqui
            return X_modificado
    ```
3. Registre a nova transforma√ß√£o no pipeline em `src/inference/engine/inference_engine.py`, adicionando uma verifica√ß√£o no construtor e incluindo no pipeline.

4. Adicione um campo correspondente (se desejar configur√°vel) no `DataNoiseConfig` (`src/utils/types.py`).

5. Utilize nos experimentos via `InferencePipeline`.

### ‚úÖ 2. T√©cnicas aplicadas aos r√≥tulos (y)

Passos:
1. Crie uma nova classe em `src/inference/transformations/label/`, herdando de `LabelTransformation` (ou base similar).

2. Implemente o m√©todo `apply(self, y)`  (ou `apply(self, y, X=None, model=None`) se precisar).

3. Registre a t√©cnica no pipeline em (`src/inference/engine/label_runner.py`).

4. Configure no campo adequado em `LabelNoiseConfig` (em `src/utils/types.py`).

### ‚úÖ 3. T√©cnicas aplicadas aos par√¢metros dos modelos

Essas t√©cnicas s√£o tratadas por `SmartParameterPerturber`.

1. Crie uma nova classe de transforma√ß√£o em `src/inference/transformations/params/` herdando de `ParameterTransformation` e implementando o m√©todo `apply(self, params)`.

2. Importe e registre a nova t√©cnica no pipeline em `src/inference/engine/param_runner.py` (na lista de t√©cnicas dispon√≠veis).

3. Se necess√°rio, adicione uma flag de configura√ß√£o em `ParameterNoiseConfig` (`src/utils/types.py`).

4. O ponto de entrada para orquestra√ß√£o √© o m√©todo `apply_param_inference()` da pipeline.

#### ‚ö†Ô∏è As tr√™s categorias s√£o independentes, mas integradas por meio da `InferencePipeline`. Voc√™ pode aplicar apenas uma, duas ou todas combinadas nos seus experimentos.
---

## üß¨ Suporte a Infer√™ncia
Este framework suporta infer√™ncia sint√©tica em m√∫ltiplos n√≠veis, possibilitando testes de robustez em diferentes etapas do pipeline de IA:
## 1. Infer√™ncia nos dados (data inference)

#### T√©cnicas para simular ru√≠do, falhas e distor√ß√µes nos dados de entrada (`X`) :

- **Ru√≠do Aditivo**: `GaussianNoise, FeatureSelectiveNoise`
- **Redu√ß√£o de Precis√£o**: `TruncateDecimals, CastToInt, Quantize`
- **Perturba√ß√£o Estrutural**: `ShuffleFeatures, ScaleFeatures, RemoveFeatures, FeatureSwap`
- **Corrup√ß√£o Direta**: `ZeroOut, InsertNaN`
- **Outliers**: `InjectOutliers`
- **Distra√ß√£o Sem√¢ntica**: `AddDummyFeatures, DuplicateFeatures`
- **Perturba√ß√µes tabulares avan√ßadas**: `RandomMissingBlock`, `DistributionShiftMixing`, `ClusterSwap`, `GroupOutlierInjection`, `TemporalDriftInjection`.

## 2. Infer√™ncia nos r√≥tulos (label inference)
#### T√©cnicas para simular erros e ambiguidade nos r√≥tulos (`y`):
- **Ru√≠do aleat√≥rio**: `RandomLabelNoise`
- **Ru√≠do guiado por matriz de confus√£o:** `LabelConfusionMatrixNoise`
- **Flip near border** (baixa confian√ßa do modelo): `LabelFlipNearBorder`
- **Ambiguidade parcial**: `PartialLabelNoise`
- **Troca de r√≥tulos dentro de classes**: `LabelSwapWithinClass`

## 3. Infer√™ncia em par√¢metros (parameter inference)
#### O `SmartParameterPerturber` realiza muta√ß√µes autom√°ticas e validadas em hiperpar√¢metros dos modelos, incluindo:
- **Altera√ß√µes baseadas em tipo**: (`int`, `float`, `str`, `bool`)
- **Estrat√©gias**: `add_noise`, `cast`, `drop`, `flip`, entre outras.
- **Filtros por nome de par√¢metro e valida√ß√£o autom√°tica do modelo**
- **Gera√ß√£o de logs JSON para rastreamento das infer√™ncias aplicadas**.

#### ‚ö° Nota: As tr√™s categorias s√£o independentes, mas integradas via a `InferencePipeline`. Voc√™ pode aplicar apenas uma, duas ou todas as infer√™ncias combinadas em seus experimentos.

## üß© Enumera√ß√µes e Tipagens do Framework
As defini√ß√µes que padronizam origem de dados, nomes de datasets, modos de relat√≥rio e configs de perturba√ß√£o ficam em  `src/utils/types.py`

- **DatasetSourceType** ‚Üí origem dos dados: `SKLEARN`, `CSV`.
- **SklearnDatasetName** ‚Üí conjuntos suportados: `IRIS`, `WINE`, `BREAST_CANCER`, `DIGITS`.
- **CSVDatasetName** ‚Üí atalhos de CSV (ex.: `TITANIC`) com propriedade `.path`.
- **ReportMode** ‚Üí destino do output: `PRINT` (console), `JSON_LOG` (`logs/`), `JSON_RESULT` (`results/`).

### üîß Configura√ß√µes de Perturba√ß√£o (Pydantic)

O framework utiliza **Pydantic** para gerenciar e validar as configura√ß√µes de perturba√ß√£o em **dados (X)**, **r√≥tulos (y)** e **hiperpar√¢metros**.  
As configura√ß√µes s√£o definidas pelas classes `DataNoiseConfig`, `LabelNoiseConfig` e `ParameterNoiseConfig`.

---

#### üìä `DataNoiseConfig` ‚Äì Perturba√ß√µes nos Dados de Entrada (X)

Controla ru√≠dos, transforma√ß√µes estruturais e distor√ß√µes tabulares para testar robustez dos modelos.

| Categoria | Par√¢metro | Tipo / Exemplo | Descri√ß√£o |
|-----------|-----------|---------------|-----------|
| **Ru√≠do e Precis√£o** | `noise_level` | `0.1` | Intensidade de ru√≠do gaussiano. |
| | `truncate_decimals` | `2` | Trunca valores para N casas decimais. |
| | `quantize_bins` | `5` | Quantiza√ß√£o dos dados em N bins. |
| | `cast_to_int` | `True` | Converte valores para inteiros. |
| **Estrutura e Escala** | `shuffle_fraction` | `0.1` | Fra√ß√£o de colunas embaralhadas. |
| | `scale_range` | `(0.8, 1.2)` | Escala de valores (min, max). |
| | `remove_features` | `[1, 3]` | √çndices de features a remover. |
| | `feature_swap` | `[0, 2]` | √çndices de features a trocar entre si. |
| **Corrup√ß√£o e Outliers** | `zero_out_fraction` | `0.05` | Fra√ß√£o de valores zerados. |
| | `insert_nan_fraction` | `0.05` | Fra√ß√£o de `NaN`s inseridos. |
| | `outlier_fraction` | `0.05` | Fra√ß√£o de outliers aleat√≥rios. |
| **Distra√ß√µes e Redund√¢ncia** | `add_dummy_features` | `2` | N√∫mero de features fict√≠cias adicionadas. |
| | `duplicate_features` | `2` | N√∫mero de features duplicadas. |
| **Perturba√ß√µes Avan√ßadas** | `feature_selective_noise` | `(0.3, [0, 2])` | Aplica ru√≠do espec√≠fico em features selecionadas. |
| | `conditional_noise` | `(0, 5.0, 0.2)` | Ru√≠do condicional (feature, valor, desvio). |
| | `random_missing_block_fraction` | `0.1` | Por√ß√£o de blocos inteiros de dados ausentes. |
| | `distribution_shift_fraction` | `0.1` | Mudan√ßa de distribui√ß√£o simulada. |
| | `cluster_swap_fraction` | `0.1` | Troca de amostras entre clusters. |
| | `group_outlier_cluster_fraction` | `0.1` | Introdu√ß√£o de grupos de outliers. |
| | `temporal_drift_std` | `0.5` | Desvio padr√£o do drift temporal. |

---

#### üè∑Ô∏è `LabelNoiseConfig` ‚Äì Perturba√ß√µes em R√≥tulos (y)

Aplica ru√≠dos e distor√ß√µes controladas nos r√≥tulos para simular erros de anota√ß√£o.

| Par√¢metro | Tipo / Exemplo | Descri√ß√£o |
|-----------|---------------|-----------|
| `label_noise_fraction` | `0.05` | Fra√ß√£o de r√≥tulos aleatoriamente alterados. |
| `flip_near_border_fraction` | `0.05` | Troca r√≥tulos pr√≥ximos da fronteira de decis√£o. |
| `confusion_matrix_noise_level` | `0.05` | Probabilidade de ru√≠do guiado por matriz de confus√£o. |
| `partial_label_fraction` | `0.05` | Fra√ß√£o de r√≥tulos substitu√≠dos por conjuntos parciais. |
| `swap_within_class_fraction` | `0.05` | Troca de r√≥tulos dentro da mesma classe. |

---

#### ‚öôÔ∏è `ParameterNoiseConfig` ‚Äì Perturba√ß√µes em Hiperpar√¢metros

Simula cen√°rios adversos ao modificar hiperpar√¢metros de modelos.

| Par√¢metro | Tipo / Exemplo | Descri√ß√£o |
|-----------|---------------|-----------|
| `integer_noise` | `True` | Aplica ru√≠do em hiperpar√¢metros inteiros. |
| `boolean_flip` | `False` | Inverte valores booleanos. |
| `string_mutator` | `False` | Altera strings de par√¢metros (ex: nomes de otimizadores). |
| `semantic_mutation` | `False` | Perturba valores respeitando sem√¢ntica (ex: step size). |
| `scale_hyper` | `True` | Escala valores num√©ricos (multiplicativo). |
| `cross_dependency` | `False` | Perturba par√¢metros considerando depend√™ncias cruzadas. |
| `random_from_space` | `False` | Escolhe valores aleat√≥rios de espa√ßos pr√©-definidos. |
| `bounded_numeric` | `True` | Garante que valores num√©ricos fiquem em faixas v√°lidas. |
| `type_cast_perturbation` | `False` | Converte tipos dinamicamente (int ‚Üî float). |
| `enum_boundary_shift` | `False` | Escolhe pr√≥ximo valor v√°lido em enums. |

---

## üìö Objetivo

Avaliar a robustez e a sensibilidade de modelos de IA sob **perturba√ß√µes controladas** em dados, r√≥tulos e hiperpar√¢metros, simulando:

- ru√≠do e perdas de precis√£o;  
- falhas de coleta/sensores e valores ausentes;  
- outliers e mudan√ßas de distribui√ß√£o;  
- erros de anota√ß√£o e varia√ß√µes de configura√ß√£o do modelo.  

---

## üìÑ Publica√ß√£o

**Sergillam Barroso Oliveira**, **Eddie B de Lima Filho**, **Lucas Cordeiro**.  
*Modular Architecture for Robustness Assessment in AI Using Smart Inference*.  
In: **2025 IEEE 14th Global Conference on Consumer Electronics (GCCE)** ‚Äî Track OS-DSC, apresenta√ß√£o oral (*Student Paper*).  
EDAS ID: **1571156254**.  

### üìå Como citar
```bibtex
@inproceedings{oliveira2025modular,
  author    = {Sergillam Barroso Oliveira and Eddie B de Lima Filho and Lucas Cordeiro},
  title     = {Modular Architecture for Robustness Assessment in AI Using Smart Inference},
  booktitle = {Proceedings of the 2025 IEEE 14th Global Conference on Consumer Electronics (GCCE)},
  year      = {2025},
  month     = sep,
  publisher = {IEEE},
  note      = {Track: OS-DSC (Oral, Student Paper), EDAS ID: 1571156254}
}
```
---
