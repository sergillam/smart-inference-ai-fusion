# smart-inference-ai-fusion

#### Framework modular e extensÃ­vel para experimentos de inferÃªncia sintÃ©tica e perturbaÃ§Ãµes controladas em algoritmos de InteligÃªncia Artificial (IA), com foco em robustez, variabilidade e testes de falhas em datasets e hiperparÃ¢metros.

## ğŸ“ Estrutura do Projeto

```
smart-inference-ai-fusion/
â”œâ”€â”€ main.py                   # Orquestra a execuÃ§Ã£o dos experimentos
â”œâ”€â”€ run.sh                    # Script padrÃ£o de execuÃ§Ã£o
â”œâ”€â”€ datasets/                 # Arquivos CSV das bases
â”œâ”€â”€ experiments/              # Subpastas por dataset (ex: iris/, wine/)
â”‚   â””â”€â”€ iris/                 # ExperimentaÃ§Ã£o com dataset Iris
â”‚       â”œâ”€â”€ knn_iris.py       # Algoritmo KNN aplicado ao Iris
â”‚       â”œâ”€â”€ svm_iris.py       # SVM aplicado ao Iris
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ run_all.py        # Executa todos os experimentos do Iris
â”œâ”€â”€ results/                  # Logs das inferÃªncias nos parÃ¢metros
â”œâ”€â”€ src/                      # CÃ³digo-fonte do framework
â”‚   â”œâ”€â”€ core/                 # Engine base (Experiment, Model, Dataset)
â”‚   â”œâ”€â”€ datasets/             # Carregadores padronizados
â”‚   â”œâ”€â”€ inference/            # TÃ©cnicas de inferÃªncia (data e params)
â”‚   â”œâ”€â”€ models/               # ImplementaÃ§Ãµes dos algoritmos ML
â”‚   â””â”€â”€ utils/                # MÃ©tricas e relatÃ³rios
â””â”€â”€ requirements.txt          # DependÃªncias do projeto
```

## ğŸš€ Executando

### Ambiente recomendado:
- Python 3.10+
- Ambiente virtual (ex: `venv` ou `conda`)

### InstalaÃ§Ã£o:

```bash
pip install -r requirements.txt
```

### ExecuÃ§Ã£o dos experimentos:

```bash
# Forma recomendada
./run.sh

# Ou manualmente:
PYTHONPATH=src python main.py
```

## ğŸ§ª Adicionando novos experimentos

Um experimento corresponde Ã  aplicaÃ§Ã£o de um ou mais algoritmos a um mesmo conjunto de dados (dataset), com e sem inferÃªncia.

### Como adicionar um novo experimento:

1. Crie um arquivo em `experiments/<dataset>/`, por exemplo:  
   `experiments/iris/knn_iris.py`
2. Importe o modelo (ex: `KNNModel`) e o dataset loader (ex: `IrisLoader`)
3. Defina duas funÃ§Ãµes:
   - `run_<algoritmo>_without_inference()`
   - `run_<algoritmo>_with_inference()`
4. Adicione essas chamadas em `experiments/<dataset>/run_all.py`
5. No `main.py`, importe `experiments/<dataset>/run_all` via `__init__.py` da pasta

---

## ğŸ¤– Adicionando novos algoritmos

Os algoritmos sÃ£o encapsulados em classes e herdados de `BaseModel`.

### Como adicionar um novo algoritmo:

1. Crie um novo arquivo em `src/models/`, ex: `random_forest_model.py`
2. Implemente a classe `RandomForestModel`, com os mÃ©todos:
   - `train(self, X_train, y_train)`
   - `evaluate(self, X_test, y_test)` â†’ usando `evaluate_all()`
3. Use esse novo modelo em um experimento como qualquer outro

---

## ğŸ§  Adicionando novas tÃ©cnicas de inferÃªncia

TÃ©cnicas de inferÃªncia sÃ£o classes herdadas de `InferenceTransformation`, aplicadas a dados de entrada.

### Como criar uma nova tÃ©cnica:

1. Crie ou edite um arquivo em `src/inference/`, ex: `noise.py`
2. Implemente uma nova classe com o mÃ©todo `apply(self, X)`
3. Adicione a lÃ³gica correspondente no `InferenceEngine`, dentro de `apply_all()`
4. Atualize o dicionÃ¡rio `config` dos experimentos para ativar a nova tÃ©cnica

> âš ï¸ TÃ©cnicas de inferÃªncia podem ser aplicadas tanto em **X (dados)** quanto em **y (rÃ³tulos)**.

---

## ğŸ“‚ Adicionando novos datasets

Datasets sÃ£o carregados por classes que herdam de `BaseDataset`.

### Como adicionar uma nova base:

1. Coloque o arquivo `.csv` em `datasets/<nome>/`, ex: `datasets/wine/wine.csv`
2. Crie um loader em `src/datasets/`, ex: `wine_loader.py`
3. Implemente a classe `WineLoader` com os mÃ©todos:
   - `load_X_y(self)` â†’ retorna `X, y`
   - `get_labels(self)` â†’ retorna lista de classes
4. Use o loader em seus experimentos (ex: `experiments/wine/knn_wine.py`)

---

## ğŸ§  Suporte a InferÃªncia

Este framework suporta inferÃªncia em dois nÃ­veis:
## 1. InferÃªncia nos dados (data inference)

TÃ©cnicas que simulam ruÃ­do, falhas e distorÃ§Ãµes nos dados de entrada.

- RuÃ­do Aditivo: `GaussianNoise, FeatureSelectiveNoise`
- ReduÃ§Ã£o de PrecisÃ£o: `TruncateDecimals, CastToInt, Quantize`
- PerturbaÃ§Ã£o Estrutural: `ShuffleFeatures, ScaleFeatures, RemoveFeatures, FeatureSwap`
- CorrupÃ§Ã£o Direta: `ZeroOut, InsertNaN`
- Outliers: `InjectOutliers`
- DistraÃ§Ã£o SemÃ¢ntica: `AddDummyFeatures, DuplicateFeatures`
- Label Noise: `LabelNoise`

## 2. InferÃªncia em parÃ¢metros (parameter inference)
#### O `SmartParameterPerturber` realiza mutaÃ§Ãµes automÃ¡ticas e validadas em hiperparÃ¢metros dos modelos:
- AlteraÃ§Ãµes baseadas em tipo (`int`, `float`, `str`, `bool`)
- EstratÃ©gias como `add_noise`, `cast`, `drop`, `flip,` etc.
- Filtros por nome de parÃ¢metro e validaÃ§Ã£o automÃ¡tica do modelo
- GeraÃ§Ã£o de logs JSON para rastreamento de inferÃªncias aplicadas

## ğŸ“š Objetivo
Avaliar a robustez e sensibilidade de algoritmos de IA em cenÃ¡rios realistas com:

- RuÃ­do nos dados
- Falhas de coleta ou sensores
- Valores fora do padrÃ£o esperado
- PerturbaÃ§Ãµes nos parÃ¢metros do modelo
---
